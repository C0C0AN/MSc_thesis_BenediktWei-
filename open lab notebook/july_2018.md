### week 01 - 08:

- wrote a history log on [data-analysis](https://github.com/weissbe92/MSc_thesis_BenediktWeiss/blob/master/open%20lab%20notebook/analysis_steps.pdf) and worked on my (functional) preprocessing workflow in jupyter notebooks
  - prep_tnac now includes all nodes until coregistration via bbregister and works to this point (version on gdrive)
  - still to implement: coregistration for normalisation, normalisation, smoothing
  - for normalisation inform on [nipype-page](http://miykael.github.io/nipype-beginner-s-guide/normalize.html)
 
- stimuli from angulo-perkins arrived on thursday, renamed the files to voice_0-59.wav, song_0-59.wav, music_0-59.wav to fit into the nomenclatur within the run.csv-files for the psychopy-experiment (4 runfiles)
- changed the [randomisation-file](https://github.com/weissbe92/MSc_thesis_BenediktWeiss/blob/master/open%20lab%20notebook/create_run_files.py) to 4 runs and relative paths and created 4 test-csv-files
- experiment-test at scanner
- concatenated the 8 movies from mirjam to 4 movies, which have to be cutted to run-length:
  - cut movies: concatenate 2 of mirijams videos and then cut to length we need (for 4 runs) 
  - installed: sudo apt-get install mkvtoolnix mkvtoolnix-gui
  - bash-example: mkvmerge -o concat_movie7+8.mkv movie007.mkv + movie008.mkv 
  
### week 09 - 15:
  
- completed my preprocessing workflow (added normalisation-node via ants) and updated the history log on [data-analysis](https://github.com/weissbe92/MSc_thesis_BenediktWeiss/blob/master/open%20lab%20notebook/analysis_steps.pdf) afterwards
- coregistration and normalisation are now performed in one step; to compute this I oriented myself on the [nipype beginners guide](http://miykael.github.io/nipype-beginner-s-guide/normalize.html) on complete normalisation 
- test run on preproc_tnac with dataset ds000114: worked until node "convert to itk"; node needs reference file, add node fssource and convert to nii (freesurfer)
- talk on brainstem-mapping via structural and DTI MRI

### week 16 - 22:

- measured 1st participant on monday, stimuli seemed to be too quiet through the pneumatic headphones
  --> amplification up to 10 db more with audacity
  --> audacity protocol:
  
        https://www.iskysoft.com/video-editing/how-to-increase-volume-in-audacity.html#part2

        https://www.youtube.com/watch?v=TUOXerfR_08

        https://manual.audacityteam.org/man/export_multiple.html 

 
 - after correction of stimuli we measured 6 more people (sub 01-07) over the week
 - continuous updating of experimental protocol and optimisation of experiment procedure
 - preprocessing: still problems with coregistration/normalisation via ANTS, solution maybe to create own separated coregistration-workflow, because one node creating the transformation matrix needs some hours
 - runned the scripts converting to BIDS, defacing and quality control on 3 participants and further the mindboggle/freesurfer/ants structural preprocessing over the weekend (see [updated analysis protocol](https://github.com/weissbe92/MSc_thesis_BenediktWeiss/blob/master/open%20lab%20notebook/analysis_steps.pdf)
 - recruted more people for next week and organized measurement time at the scanner
 
 
