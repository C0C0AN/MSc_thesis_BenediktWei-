{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modulatory parameter estimates (B-matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "from scipy.stats import ttest_1samp, wilcoxon, mannwhitneyu\n",
    "from scipy import stats\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "#from multipy.fdr import lsu\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub 09, 10, 18 not estimated due to threshold --> 20 subjects left\n",
    "list_participants = []\n",
    "\n",
    "for part in range(2,25):\n",
    "    if part == 9:\n",
    "        continue\n",
    "    if part == 10:\n",
    "        continue\n",
    "    if part == 18:\n",
    "        continue    \n",
    "    elif part < 10:\n",
    "        list_participants.append('sub_0%s' % str(part))\n",
    "    elif part >= 10:\n",
    "        list_participants.append('sub_%s' % str(part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub 09, 10, 18 not estimated due to threshold --> 20 subjects left\n",
    "# right handed non-musicians: 02, 05, 06, 08, 14, 16, 19, 22, 24 (09, 10)\n",
    "# right handed musicians: 03, 04, 07, 11, 12, 17, 21 (18)\n",
    "# left handed non-musicians: 13, 15, 20, 23\n",
    "\n",
    "list_group = ['RH_nM','RH_M','RH_M','RH_nM','RH_nM','RH_M','RH_nM','RH_M','RH_M','LH_nM','RH_nM','LH_nM','RH_nM','RH_M','RH_nM','LH_nM','RH_M','RH_nM','LH_nM','RH_nM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group-level results, separated for RH-nM, RH-M, LH-nM and across all subs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_HG_l_HG_l = []\n",
    "list_HG_l_PP_l = []\n",
    "list_HG_l_PT_l = []\n",
    "list_HG_l_HG_r = []\n",
    "list_HG_r_HG_r = []\n",
    "list_HG_r_PP_r = []\n",
    "list_HG_r_PT_r = []\n",
    "list_HG_r_HG_l = []\n",
    "list_PP_l_HG_l = []\n",
    "list_PP_r_HG_r = []\n",
    "list_PT_l_HG_l = []\n",
    "list_PT_l_PT_r = []\n",
    "list_PT_r_HG_r = []\n",
    "list_PT_r_PT_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function global itself does not sort output!\n",
    "list_B_matrices_music = sorted(glob('/home/benedikt/Desktop/AB-matrices/B_matrices_all_subjects/sub_*_B_matrix_music.mat'))\n",
    "list_B_matrices_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 20 participants\n",
    "con_params_B_matrices_music = pd.DataFrame(columns=['participant', 'group', 'HG_l → HG_l', 'HG_l → PP_l', 'HG_l → PT_l', \n",
    "                                   'HG_l → HG_r', 'HG_r → HG_r', 'HG_r → PP_r', 'HG_r → PT_r', 'HG_r → HG_l',\n",
    "                                   'PP_l → HG_l', 'PP_r → HG_r', 'PT_l → HG_l', 'PT_l → PT_r', 'PT_r → HG_r', 'PT_r → PT_l'], index=range(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_params_B_matrices_music['group'] = list_group\n",
    "con_params_B_matrices_music['participant'] = list_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat, part in zip(list_B_matrices_music, list_participants):\n",
    "     \n",
    "    \n",
    "    \n",
    "    part_df = loadmat(mat)['%s_B_matrix_music' % part]  \n",
    "    \n",
    "    list_HG_l_HG_l.append(part_df[0,0])\n",
    "    list_HG_l_PP_l.append(part_df[4,0])\n",
    "    list_HG_l_PT_l.append(part_df[2,0])\n",
    "    list_HG_l_HG_r.append(part_df[1,0])\n",
    "    list_HG_r_HG_r.append(part_df[1,1])\n",
    "    list_HG_r_PP_r.append(part_df[5,1])\n",
    "    list_HG_r_PT_r.append(part_df[3,1])\n",
    "    list_HG_r_HG_l.append(part_df[0,1])\n",
    "    list_PP_l_HG_l.append(part_df[0,4])\n",
    "    list_PP_r_HG_r.append(part_df[1,5])\n",
    "    list_PT_l_HG_l.append(part_df[0,2])\n",
    "    list_PT_l_PT_r.append(part_df[3,2])\n",
    "    list_PT_r_HG_r.append(part_df[1,3])\n",
    "    list_PT_r_PT_l.append(part_df[2,3])\n",
    "\n",
    "    list_connections = [list_HG_l_HG_l, list_HG_l_PP_l, list_HG_l_PT_l, list_HG_l_HG_r, list_HG_r_HG_r, list_HG_r_PP_r,\n",
    "                    list_HG_r_PT_r, list_HG_r_HG_l, list_PP_l_HG_l, list_PP_r_HG_r, list_PT_l_HG_l, list_PT_l_PT_r,\n",
    "                    list_PT_r_HG_r, list_PT_r_PT_l]\n",
    "    \n",
    "for key, con in zip(con_params_B_matrices_music.keys()[2:,], list_connections):\n",
    "\n",
    "    con_params_B_matrices_music[key] = con\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reihenfolge regionen in matrizen: lhHg, rhHG, lhPT, rhPT, lhPP, rhPP:\n",
    "\n",
    "#  HG_l_HG_l HG_r_HG_l PT_l_HG_l PT_r_HG_l PP_l_HG_l PP_r_HG_l\n",
    "#  HG_l_HG_r HG_r_HG_r ...\n",
    "#  HG_l_PT_l HG_r_PT_l ...\n",
    "#  HG_l_PT_r HG_r_PT_r ...\n",
    "#  HG_l_PP_l HG_r_PP_l ...\n",
    "#  HG_l_PP_r HG_r_PP_r ...  \n",
    "\n",
    "# e.g., sub_02_B_matrix_music =\n",
    "\n",
    "#   0.57107   0.00000   0.00000   0.00000   0.00000   0.00000\n",
    "#  -1.32051  -2.93957   0.00000  -0.81440   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000  -0.52791   0.00000   0.00000\n",
    "#   0.00000   0.96735   0.00000   0.00000   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.00000   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.00000   0.00000   0.00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_params_B_matrices_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort data frame after groups and split into 3 separated frames\n",
    "sorted_file = con_params_B_matrices_music.sort_values('group')\n",
    "\n",
    "con_params_music_lhnm = sorted_file.iloc[0:4]\n",
    "con_params_music_rhm = sorted_file.iloc[4:11]\n",
    "con_params_music_rhnm = sorted_file.iloc[11:,]\n",
    "\n",
    "display(con_params_music_rhnm)\n",
    "display(con_params_music_rhm)\n",
    "display(con_params_music_lhnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### music-allsubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_B_matrices_music.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "allsubs_music_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_music.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_B_matrices_music[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_B_matrices_music[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_shapiro['statistic'] = list_shap_t\n",
    "allsubs_music_shapiro['p value'] = list_shap_p\n",
    "allsubs_music_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "allsubs_music_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "allsubs_music_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_music.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_B_matrices_music[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_B_matrices_music[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "allsubs_music_wilcoxon['p value'] = list_wilcoxon_p\n",
    "allsubs_music_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_B_matrices_music.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_B_matrices_music[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_B_matrices_music[con].std(), 12))\n",
    "    list_medians.append(round(con_params_B_matrices_music[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_B_matrices_music[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_B_matrices_music[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_B_matrices_music[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_B_matrices_music[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_B_matrices_music[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_stats['mean'] = list_means\n",
    "allsubs_music_stats['sd']   = list_sd\n",
    "allsubs_music_stats['median'] = list_medians\n",
    "allsubs_music_stats['t_statistic'] = list_t\n",
    "allsubs_music_stats['p_value'] = list_p\n",
    "allsubs_music_stats['cohen-d'] = list_cohen_d\n",
    "allsubs_music_stats['power'] = list_power\n",
    "allsubs_music_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### music-rhnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_music_rhnm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "rhnm_music_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_music_rhnm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_music_rhnm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_music_shapiro['statistic'] = list_shap_t\n",
    "rhnm_music_shapiro['p value'] = list_shap_p\n",
    "rhnm_music_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "rhnm_music_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "rhnm_music_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_music_rhnm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_music_rhnm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_music_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "rhnm_music_wilcoxon['p value'] = list_wilcoxon_p\n",
    "rhnm_music_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_music_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_music_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_music_rhnm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_music_rhnm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_music_rhnm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_music_rhnm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_music_rhnm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_music_rhnm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_music_rhnm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_music_rhnm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_music_stats['mean'] = list_means\n",
    "rhnm_music_stats['sd']   = list_sd\n",
    "rhnm_music_stats['median'] = list_medians\n",
    "rhnm_music_stats['t_statistic'] = list_t\n",
    "rhnm_music_stats['p_value'] = list_p\n",
    "rhnm_music_stats['cohen-d'] = list_cohen_d\n",
    "rhnm_music_stats['power'] = list_power\n",
    "rhnm_music_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_music_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### music-rhm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_music_rhm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "rhm_music_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_music_rhm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_music_rhm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_music_shapiro['statistic'] = list_shap_t\n",
    "rhm_music_shapiro['p value'] = list_shap_p\n",
    "rhm_music_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "rhm_music_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "rhm_music_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_music_rhm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_music_rhm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_music_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "rhm_music_wilcoxon['p value'] = list_wilcoxon_p\n",
    "rhm_music_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_music_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_music_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_music_rhm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_music_rhm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_music_rhm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_music_rhm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_music_rhm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_music_rhm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_music_rhm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_music_rhm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_music_stats['mean'] = list_means\n",
    "rhm_music_stats['sd']   = list_sd\n",
    "rhm_music_stats['median'] = list_medians\n",
    "rhm_music_stats['t_statistic'] = list_t\n",
    "rhm_music_stats['p_value'] = list_p\n",
    "rhm_music_stats['cohen-d'] = list_cohen_d\n",
    "rhm_music_stats['power'] = list_power\n",
    "rhm_music_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_music_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### music-lhnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_music_lhnm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "lhnm_music_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_music_lhnm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_music_lhnm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_music_shapiro['statistic'] = list_shap_t\n",
    "lhnm_music_shapiro['p value'] = list_shap_p\n",
    "lhnm_music_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "lhnm_music_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "lhnm_music_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_music_lhnm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_music_lhnm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_music_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "lhnm_music_wilcoxon['p value'] = list_wilcoxon_p\n",
    "lhnm_music_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_music_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_music_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_music_lhnm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_music_lhnm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_music_lhnm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_music_lhnm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_music_lhnm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_music_lhnm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_music_lhnm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_music_lhnm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_music_stats['mean'] = list_means\n",
    "lhnm_music_stats['sd']   = list_sd\n",
    "lhnm_music_stats['median'] = list_medians\n",
    "lhnm_music_stats['t_statistic'] = list_t\n",
    "lhnm_music_stats['p_value'] = list_p\n",
    "lhnm_music_stats['cohen-d'] = list_cohen_d\n",
    "lhnm_music_stats['power'] = list_power\n",
    "lhnm_music_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_music_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## singing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Group-level results, separated for RH-nM, RH-M, LH-nM and across all subs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_HG_l_HG_l = []\n",
    "list_HG_l_PP_l = []\n",
    "list_HG_l_PT_l = []\n",
    "list_HG_l_HG_r = []\n",
    "list_HG_r_HG_r = []\n",
    "list_HG_r_PP_r = []\n",
    "list_HG_r_PT_r = []\n",
    "list_HG_r_HG_l = []\n",
    "list_PP_l_HG_l = []\n",
    "list_PP_r_HG_r = []\n",
    "list_PT_l_HG_l = []\n",
    "list_PT_l_PT_r = []\n",
    "list_PT_r_HG_r = []\n",
    "list_PT_r_PT_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function global itself does not sort output!\n",
    "list_B_matrices_singing = sorted(glob('/home/benedikt/Desktop/AB-matrices/B_matrices_all_subjects/sub_*_singing.mat'))\n",
    "list_B_matrices_singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 20 participants\n",
    "con_params_B_matrices_singing = pd.DataFrame(columns=['participant', 'group', 'HG_l → HG_l', 'HG_l → PP_l', 'HG_l → PT_l', \n",
    "                                   'HG_l → HG_r', 'HG_r → HG_r', 'HG_r → PP_r', 'HG_r → PT_r', 'HG_r → HG_l',\n",
    "                                   'PP_l → HG_l', 'PP_r → HG_r', 'PT_l → HG_l', 'PT_l → PT_r', 'PT_r → HG_r', 'PT_r → PT_l'], index=range(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_params_B_matrices_singing['group'] = list_group\n",
    "con_params_B_matrices_singing['participant'] = list_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat, part in zip(list_B_matrices_singing, list_participants):\n",
    "     \n",
    "    \n",
    "    \n",
    "    part_df = loadmat(mat)['%s_B_matrix_singing' % part]  \n",
    "    \n",
    "    list_HG_l_HG_l.append(part_df[0,0])\n",
    "    list_HG_l_PP_l.append(part_df[4,0])\n",
    "    list_HG_l_PT_l.append(part_df[2,0])\n",
    "    list_HG_l_HG_r.append(part_df[1,0])\n",
    "    list_HG_r_HG_r.append(part_df[1,1])\n",
    "    list_HG_r_PP_r.append(part_df[5,1])\n",
    "    list_HG_r_PT_r.append(part_df[3,1])\n",
    "    list_HG_r_HG_l.append(part_df[0,1])\n",
    "    list_PP_l_HG_l.append(part_df[0,4])\n",
    "    list_PP_r_HG_r.append(part_df[1,5])\n",
    "    list_PT_l_HG_l.append(part_df[0,2])\n",
    "    list_PT_l_PT_r.append(part_df[3,2])\n",
    "    list_PT_r_HG_r.append(part_df[1,3])\n",
    "    list_PT_r_PT_l.append(part_df[2,3])\n",
    "\n",
    "    list_connections = [list_HG_l_HG_l, list_HG_l_PP_l, list_HG_l_PT_l, list_HG_l_HG_r, list_HG_r_HG_r, list_HG_r_PP_r,\n",
    "                    list_HG_r_PT_r, list_HG_r_HG_l, list_PP_l_HG_l, list_PP_r_HG_r, list_PT_l_HG_l, list_PT_l_PT_r,\n",
    "                    list_PT_r_HG_r, list_PT_r_PT_l]\n",
    "    \n",
    "for key, con in zip(con_params_B_matrices_singing.keys()[2:,], list_connections):\n",
    "\n",
    "    con_params_B_matrices_singing[key] = con\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., sub_02_B_matrix_singing =\n",
    "\n",
    "#   0.09957   0.00000   0.00000   0.00000   0.00000   0.00000\n",
    "#  -2.46078  -2.28239   0.00000  -0.43736   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000  -0.26064   0.00000   0.00000\n",
    "#   0.00000   1.15456   0.00000   0.00000   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.00000   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.00000   0.00000   0.00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_params_B_matrices_singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort data frame after groups and split into 3 separated frames\n",
    "sorted_file = con_params_B_matrices_singing.sort_values('group')\n",
    "\n",
    "con_params_singing_lhnm = sorted_file.iloc[0:4]\n",
    "con_params_singing_rhm = sorted_file.iloc[4:11]\n",
    "con_params_singing_rhnm = sorted_file.iloc[11:,]\n",
    "\n",
    "display(con_params_singing_rhnm)\n",
    "display(con_params_singing_rhm)\n",
    "display(con_params_singing_lhnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singing-allsubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_B_matrices_singing.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "allsubs_singing_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_singing.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_B_matrices_singing[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_B_matrices_singing[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_singing_shapiro['statistic'] = list_shap_t\n",
    "allsubs_singing_shapiro['p value'] = list_shap_p\n",
    "allsubs_singing_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "allsubs_singing_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "allsubs_singing_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_singing.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_B_matrices_singing[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_B_matrices_singing[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_singing_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "allsubs_singing_wilcoxon['p value'] = list_wilcoxon_p\n",
    "allsubs_singing_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_singing_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_B_matrices_singing.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_B_matrices_singing[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_B_matrices_singing[con].std(), 12))\n",
    "    list_medians.append(round(con_params_B_matrices_singing[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_B_matrices_singing[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_B_matrices_singing[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_B_matrices_singing[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_B_matrices_singing[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_B_matrices_singing[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_singing_stats['mean'] = list_means\n",
    "allsubs_singing_stats['sd']   = list_sd\n",
    "allsubs_singing_stats['median'] = list_medians\n",
    "allsubs_singing_stats['t_statistic'] = list_t\n",
    "allsubs_singing_stats['p_value'] = list_p\n",
    "allsubs_singing_stats['cohen-d'] = list_cohen_d\n",
    "allsubs_singing_stats['power'] = list_power\n",
    "allsubs_singing_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_singing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singing-rhnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_singing_rhnm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "rhnm_singing_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_singing_rhnm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_singing_rhnm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_singing_shapiro['statistic'] = list_shap_t\n",
    "rhnm_singing_shapiro['p value'] = list_shap_p\n",
    "rhnm_singing_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "rhnm_singing_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "rhnm_singing_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_singing_rhnm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_singing_rhnm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_singing_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "rhnm_singing_wilcoxon['p value'] = list_wilcoxon_p\n",
    "rhnm_singing_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_singing_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_singing_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_singing_rhnm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_singing_rhnm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_singing_rhnm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_singing_rhnm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_singing_rhnm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_singing_rhnm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_singing_rhnm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_singing_rhnm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_singing_stats['mean'] = list_means\n",
    "rhnm_singing_stats['sd']   = list_sd\n",
    "rhnm_singing_stats['median'] = list_medians\n",
    "rhnm_singing_stats['t_statistic'] = list_t\n",
    "rhnm_singing_stats['p_value'] = list_p\n",
    "rhnm_singing_stats['cohen-d'] = list_cohen_d\n",
    "rhnm_singing_stats['power'] = list_power\n",
    "rhnm_singing_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_singing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singing-rhm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_singing_rhm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "rhm_singing_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_singing_rhm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_singing_rhm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_singing_shapiro['statistic'] = list_shap_t\n",
    "rhm_singing_shapiro['p value'] = list_shap_p\n",
    "rhm_singing_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "rhm_singing_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "rhm_singing_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_singing_rhm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_singing_rhm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_singing_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "rhm_singing_wilcoxon['p value'] = list_wilcoxon_p\n",
    "rhm_singing_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_singing_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_singing_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_singing_rhm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_singing_rhm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_singing_rhm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_singing_rhm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_singing_rhm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_singing_rhm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_singing_rhm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_singing_rhm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_singing_stats['mean'] = list_means\n",
    "rhm_singing_stats['sd']   = list_sd\n",
    "rhm_singing_stats['median'] = list_medians\n",
    "rhm_singing_stats['t_statistic'] = list_t\n",
    "rhm_singing_stats['p_value'] = list_p\n",
    "rhm_singing_stats['cohen-d'] = list_cohen_d\n",
    "rhm_singing_stats['power'] = list_power\n",
    "rhm_singing_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_singing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singing-lhnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_singing_lhnm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "lhnm_singing_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_singing_lhnm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_singing_lhnm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_singing_shapiro['statistic'] = list_shap_t\n",
    "lhnm_singing_shapiro['p value'] = list_shap_p\n",
    "lhnm_singing_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "lhnm_singing_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "lhnm_singing_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_singing_lhnm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_singing_lhnm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_singing_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "lhnm_singing_wilcoxon['p value'] = list_wilcoxon_p\n",
    "lhnm_singing_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_singing_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_singing_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_singing_lhnm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_singing_lhnm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_singing_lhnm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_singing_lhnm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_singing_lhnm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_singing_lhnm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_singing_lhnm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_singing_lhnm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_singing_stats['mean'] = list_means\n",
    "lhnm_singing_stats['sd']   = list_sd\n",
    "lhnm_singing_stats['median'] = list_medians\n",
    "lhnm_singing_stats['t_statistic'] = list_t\n",
    "lhnm_singing_stats['p_value'] = list_p\n",
    "lhnm_singing_stats['cohen-d'] = list_cohen_d\n",
    "lhnm_singing_stats['power'] = list_power\n",
    "lhnm_singing_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_singing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Group-level results, separated for RH-nM, RH-M, LH-nM and across all subs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_HG_l_HG_l = []\n",
    "list_HG_l_PP_l = []\n",
    "list_HG_l_PT_l = []\n",
    "list_HG_l_HG_r = []\n",
    "list_HG_r_HG_r = []\n",
    "list_HG_r_PP_r = []\n",
    "list_HG_r_PT_r = []\n",
    "list_HG_r_HG_l = []\n",
    "list_PP_l_HG_l = []\n",
    "list_PP_r_HG_r = []\n",
    "list_PT_l_HG_l = []\n",
    "list_PT_l_PT_r = []\n",
    "list_PT_r_HG_r = []\n",
    "list_PT_r_PT_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function global itself does not sort output!\n",
    "list_B_matrices_speech = sorted(glob('/home/benedikt/Desktop/AB-matrices/B_matrices_all_subjects/sub_*_speech.mat'))\n",
    "list_B_matrices_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 20 participants\n",
    "con_params_B_matrices_speech = pd.DataFrame(columns=['participant', 'group', 'HG_l → HG_l', 'HG_l → PP_l', 'HG_l → PT_l', \n",
    "                                   'HG_l → HG_r', 'HG_r → HG_r', 'HG_r → PP_r', 'HG_r → PT_r', 'HG_r → HG_l',\n",
    "                                   'PP_l → HG_l', 'PP_r → HG_r', 'PT_l → HG_l', 'PT_l → PT_r', 'PT_r → HG_r', 'PT_r → PT_l'], index=range(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_params_B_matrices_speech['group'] = list_group\n",
    "con_params_B_matrices_speech['participant'] = list_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat, part in zip(list_B_matrices_speech, list_participants):\n",
    "     \n",
    "    \n",
    "    \n",
    "    part_df = loadmat(mat)['%s_B_matrix_speech' % part]  \n",
    "    \n",
    "    list_HG_l_HG_l.append(part_df[0,0])\n",
    "    list_HG_l_PP_l.append(part_df[4,0])\n",
    "    list_HG_l_PT_l.append(part_df[2,0])\n",
    "    list_HG_l_HG_r.append(part_df[1,0])\n",
    "    list_HG_r_HG_r.append(part_df[1,1])\n",
    "    list_HG_r_PP_r.append(part_df[5,1])\n",
    "    list_HG_r_PT_r.append(part_df[3,1])\n",
    "    list_HG_r_HG_l.append(part_df[0,1])\n",
    "    list_PP_l_HG_l.append(part_df[0,4])\n",
    "    list_PP_r_HG_r.append(part_df[1,5])\n",
    "    list_PT_l_HG_l.append(part_df[0,2])\n",
    "    list_PT_l_PT_r.append(part_df[3,2])\n",
    "    list_PT_r_HG_r.append(part_df[1,3])\n",
    "    list_PT_r_PT_l.append(part_df[2,3])\n",
    "\n",
    "    list_connections = [list_HG_l_HG_l, list_HG_l_PP_l, list_HG_l_PT_l, list_HG_l_HG_r, list_HG_r_HG_r, list_HG_r_PP_r,\n",
    "                    list_HG_r_PT_r, list_HG_r_HG_l, list_PP_l_HG_l, list_PP_r_HG_r, list_PT_l_HG_l, list_PT_l_PT_r,\n",
    "                    list_PT_r_HG_r, list_PT_r_PT_l]\n",
    "    \n",
    "for key, con in zip(con_params_B_matrices_speech.keys()[2:,], list_connections):\n",
    "\n",
    "    con_params_B_matrices_speech[key] = con\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., sub_02_B_matrix_speech =\n",
    "\n",
    "#  -0.34940   0.00000   0.00000   0.00000   0.00000   0.00000\n",
    "#   1.16696   0.18656   0.00000  -1.87339   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.04519   0.00000   0.00000\n",
    "#   0.00000   1.32836   0.00000   0.00000   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.00000   0.00000   0.00000\n",
    "#   0.00000   0.00000   0.00000   0.00000   0.00000   0.00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_params_B_matrices_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort data frame after groups and split into 3 separated frames\n",
    "sorted_file = con_params_B_matrices_speech.sort_values('group')\n",
    "\n",
    "con_params_speech_lhnm = sorted_file.iloc[0:4]\n",
    "con_params_speech_rhm = sorted_file.iloc[4:11]\n",
    "con_params_speech_rhnm = sorted_file.iloc[11:,]\n",
    "\n",
    "display(con_params_speech_rhnm)\n",
    "display(con_params_speech_rhm)\n",
    "display(con_params_speech_lhnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speech-allsubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_B_matrices_speech.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "allsubs_speech_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_speech.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_B_matrices_speech[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_B_matrices_speech[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_shapiro['statistic'] = list_shap_t\n",
    "allsubs_speech_shapiro['p value'] = list_shap_p\n",
    "allsubs_speech_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "allsubs_speech_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "allsubs_speech_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_speech.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_B_matrices_speech[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_B_matrices_speech[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "allsubs_speech_wilcoxon['p value'] = list_wilcoxon_p\n",
    "allsubs_speech_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_B_matrices_speech.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_B_matrices_speech[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_B_matrices_speech[con].std(), 12))\n",
    "    list_medians.append(round(con_params_B_matrices_speech[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_B_matrices_speech[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_B_matrices_speech[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_B_matrices_speech[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_B_matrices_speech[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_B_matrices_speech[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_stats['mean'] = list_means\n",
    "allsubs_speech_stats['sd']   = list_sd\n",
    "allsubs_speech_stats['median'] = list_medians\n",
    "allsubs_speech_stats['t_statistic'] = list_t\n",
    "allsubs_speech_stats['p_value'] = list_p\n",
    "allsubs_speech_stats['cohen-d'] = list_cohen_d\n",
    "allsubs_speech_stats['power'] = list_power\n",
    "allsubs_speech_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speech-rhnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_speech_rhnm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "rhnm_speech_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_speech_rhnm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_speech_rhnm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_speech_shapiro['statistic'] = list_shap_t\n",
    "rhnm_speech_shapiro['p value'] = list_shap_p\n",
    "rhnm_speech_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "rhnm_speech_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "rhnm_speech_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_speech_rhnm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_speech_rhnm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_speech_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "rhnm_speech_wilcoxon['p value'] = list_wilcoxon_p\n",
    "rhnm_speech_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_speech_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_speech_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_speech_rhnm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_speech_rhnm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_speech_rhnm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_speech_rhnm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_speech_rhnm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_speech_rhnm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_speech_rhnm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_speech_rhnm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_speech_stats['mean'] = list_means\n",
    "rhnm_speech_stats['sd']   = list_sd\n",
    "rhnm_speech_stats['median'] = list_medians\n",
    "rhnm_speech_stats['t_statistic'] = list_t\n",
    "rhnm_speech_stats['p_value'] = list_p\n",
    "rhnm_speech_stats['cohen-d'] = list_cohen_d\n",
    "rhnm_speech_stats['power'] = list_power\n",
    "rhnm_speech_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_speech_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speech-rhm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_speech_rhm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "rhm_speech_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_speech_rhm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_speech_rhm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_speech_shapiro['statistic'] = list_shap_t\n",
    "rhm_speech_shapiro['p value'] = list_shap_p\n",
    "rhm_speech_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "rhm_speech_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "rhm_speech_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_speech_rhm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_speech_rhm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_speech_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "rhm_speech_wilcoxon['p value'] = list_wilcoxon_p\n",
    "rhm_speech_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_speech_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_speech_rhm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_speech_rhm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_speech_rhm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_speech_rhm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_speech_rhm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_speech_rhm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_speech_rhm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_speech_rhm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_speech_rhm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_speech_stats['mean'] = list_means\n",
    "rhm_speech_stats['sd']   = list_sd\n",
    "rhm_speech_stats['median'] = list_medians\n",
    "rhm_speech_stats['t_statistic'] = list_t\n",
    "rhm_speech_stats['p_value'] = list_p\n",
    "rhm_speech_stats['cohen-d'] = list_cohen_d\n",
    "rhm_speech_stats['power'] = list_power\n",
    "rhm_speech_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_speech_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speech-lhnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix = con_params_speech_lhnm.keys()[2:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"shapiro-wilk-signifikanztest für kleine stichprobengrößen\"\n",
    "lhnm_speech_shapiro = pd.DataFrame(columns=['statistic', 'p value', 'norm'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shap_t = []\n",
    "list_shap_p = []\n",
    "list_shap_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.shapiro (scipy): performs the Shapiro-Wilk test for normality.\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution\n",
    "# Statistik über sämtliche parameter innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_shap_t.append(round(stats.shapiro(con_params_speech_lhnm[con])[0], 12))\n",
    "    list_shap_p.append(round(stats.shapiro(con_params_speech_lhnm[con])[1], 12))\n",
    "    \n",
    "for p in list_shap_p:\n",
    "    if p > 0.05:\n",
    "        list_shap_norm.append('True')\n",
    "    else:\n",
    "        list_shap_norm.append('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_speech_shapiro['statistic'] = list_shap_t\n",
    "lhnm_speech_shapiro['p value'] = list_shap_p\n",
    "lhnm_speech_shapiro['norm'] = list_shap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn p-wert kleiner 0.05, dann stichprobendaten nicht normalverteilt, d.h. H0 abgelehnt (\"es gibt also signifikanten unterschied\")\n",
    "lhnm_speech_shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-sample wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-parametric wilcoxon-test\n",
    "lhnm_speech_wilcoxon = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wilcoxon_stats = []\n",
    "list_wilcoxon_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_wilcoxon_stats.append(round(stats.wilcoxon(con_params_speech_lhnm[con] - 0)[0], 12))\n",
    "    list_wilcoxon_p.append(round(stats.wilcoxon(con_params_speech_lhnm[con] - 0)[1], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_speech_wilcoxon['statistic'] = list_wilcoxon_stats\n",
    "lhnm_speech_wilcoxon['p value'] = list_wilcoxon_p\n",
    "lhnm_speech_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean, sd, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_speech_stats = pd.DataFrame(columns=['mean', 'sd', 'median', 't_statistic', 'p_value', 'cohen-d', 'power', 'BF10'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_sd = []\n",
    "list_medians = []\n",
    "list_t = []\n",
    "list_p = []\n",
    "list_cohen_d = []\n",
    "list_power = []\n",
    "list_bayesfactor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests via module pingouin (pg)\n",
    "for con in con_params_speech_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_means.append(round(con_params_speech_lhnm[con].mean(), 12))\n",
    "    list_sd.append(round(con_params_speech_lhnm[con].std(), 12))\n",
    "    list_medians.append(round(con_params_speech_lhnm[con].median(), 12))\n",
    "    list_t.append(round(pg.ttest(con_params_speech_lhnm[con],0)['T'][0], 12))\n",
    "    list_p.append(round(pg.ttest(con_params_speech_lhnm[con],0)['p-val'][0], 12))\n",
    "    list_cohen_d.append(round(pg.ttest(con_params_speech_lhnm[con],0)['cohen-d'][0], 12))\n",
    "    list_power.append(round(pg.ttest(con_params_speech_lhnm[con],0)['power'][0], 12))\n",
    "    list_bayesfactor.append(round(pg.ttest(con_params_speech_lhnm[con],0)['BF10'][0], 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_speech_stats['mean'] = list_means\n",
    "lhnm_speech_stats['sd']   = list_sd\n",
    "lhnm_speech_stats['median'] = list_medians\n",
    "lhnm_speech_stats['t_statistic'] = list_t\n",
    "lhnm_speech_stats['p_value'] = list_p\n",
    "lhnm_speech_stats['cohen-d'] = list_cohen_d\n",
    "lhnm_speech_stats['power'] = list_power\n",
    "lhnm_speech_stats['BF10'] = list_bayesfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_speech_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/benedikt/Desktop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mux = pd.MultiIndex.from_product([['music_allsubs','music_RH-nM','music_RH-M','music_LH-nM'], ['mean', 'std', 'median', 'p_value']])\n",
    "inspection = pd.DataFrame(columns=mux, index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection[('music_allsubs','median')] = allsubs_music_stats['median']\n",
    "inspection[('music_allsubs','mean')] = allsubs_music_stats['mean'] \n",
    "inspection[('music_allsubs','std')] = allsubs_music_stats['sd'] \n",
    "inspection[('music_allsubs','p_value')] = allsubs_music_wilcoxon['p value']\n",
    "\n",
    "inspection[('music_RH-nM','median')] = rhnm_music_stats['median']\n",
    "inspection[('music_RH-nM','mean')] = rhnm_music_stats['mean']\n",
    "inspection[('music_RH-nM','std')] = rhnm_music_stats['sd']\n",
    "inspection[('music_RH-nM','p_value')] = rhnm_music_wilcoxon['p value']\n",
    "\n",
    "inspection[('music_RH-M','median')] = rhm_music_stats['median']\n",
    "inspection[('music_RH-M','mean')] = rhm_music_stats['mean']\n",
    "inspection[('music_RH-M','std')] = rhm_music_stats['sd']\n",
    "inspection[('music_RH-M','p_value')] = rhm_music_wilcoxon['p value']\n",
    "\n",
    "inspection[('music_LH-nM','median')] = lhnm_music_stats['median']\n",
    "inspection[('music_LH-nM','mean')] = lhnm_music_stats['mean']\n",
    "inspection[('music_LH-nM','std')] = lhnm_music_stats['sd']\n",
    "inspection[('music_LH-nM','p_value')] = lhnm_music_wilcoxon['p value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs = inspection.iloc[:,0:4]\n",
    " \n",
    "table_allsubs = allsubs.to_csv('statistics_B-matrices_music_allsubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm = inspection.iloc[:,4:8]\n",
    " \n",
    "table_rhnm = rhnm.to_csv('statistics_B-matrices_music_rhnm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm = inspection.iloc[:,8:12]\n",
    " \n",
    "table_rhm = rhm.to_csv('statistics_B-matrices_music_rhm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lhnm = inspection.iloc[:,12:16]\n",
    " \n",
    "table_lhnm = lhnm.to_csv('statistics_B-matrices_music_lhnm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mux_2 = pd.MultiIndex.from_product([['speech_allsubs','speech_RH-nM','speech_RH-M','speech_LH-nM'], ['mean', 'std', 'median', 'p_value']])\n",
    "inspection_2 = pd.DataFrame(columns=mux_2, index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_2[('speech_allsubs','median')] = allsubs_speech_stats['median']\n",
    "inspection_2[('speech_allsubs','mean')] = allsubs_speech_stats['mean'] \n",
    "inspection_2[('speech_allsubs','std')] = allsubs_speech_stats['sd'] \n",
    "inspection_2[('speech_allsubs','p_value')] = allsubs_speech_wilcoxon['p value']\n",
    "\n",
    "inspection_2[('speech_RH-nM','median')] = rhnm_speech_stats['median']\n",
    "inspection_2[('speech_RH-nM','mean')] = rhnm_speech_stats['mean']\n",
    "inspection_2[('speech_RH-nM','std')] = rhnm_speech_stats['sd']\n",
    "inspection_2[('speech_RH-nM','p_value')] = rhnm_speech_wilcoxon['p value']\n",
    "\n",
    "inspection_2[('speech_RH-M','median')] = rhm_speech_stats['median']\n",
    "inspection_2[('speech_RH-M','mean')] = rhm_speech_stats['mean']\n",
    "inspection_2[('speech_RH-M','std')] = rhm_speech_stats['sd']\n",
    "inspection_2[('speech_RH-M','p_value')] = rhm_speech_wilcoxon['p value']\n",
    "\n",
    "inspection_2[('speech_LH-nM','median')] = lhnm_speech_stats['median']\n",
    "inspection_2[('speech_LH-nM','mean')] = lhnm_speech_stats['mean']\n",
    "inspection_2[('speech_LH-nM','std')] = lhnm_speech_stats['sd']\n",
    "inspection_2[('speech_LH-nM','p_value')] = lhnm_speech_wilcoxon['p value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspection_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_2 = inspection_2.iloc[:,0:4]\n",
    "table_allsubs_2 = allsubs_2.to_csv('statistics_B-matrices_speech_allsubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_2 = inspection_2.iloc[:,4:8]\n",
    "table_rhnm_2 = rhnm_2.to_csv('statistics_B-matrices_speech_rhnm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_2 = inspection_2.iloc[:,8:12]\n",
    "table_rhm_2 = rhm_2.to_csv('statistics_B-matrices_speech_rhm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_2 = inspection_2.iloc[:,12:16]\n",
    "table_lhnm_2 = lhnm_2.to_csv('statistics_B-matrices_speech_lhnm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mux_3 = pd.MultiIndex.from_product([['singing_allsubs','singing_RH-nM','singing_RH-M','singing_LH-nM'], ['mean', 'std', 'median', 'p_value']])\n",
    "inspection_3 = pd.DataFrame(columns=mux_3, index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_3[('singing_allsubs','median')] = allsubs_singing_stats['median']\n",
    "inspection_3[('singing_allsubs','mean')] = allsubs_singing_stats['mean'] \n",
    "inspection_3[('singing_allsubs','std')] = allsubs_singing_stats['sd'] \n",
    "inspection_3[('singing_allsubs','p_value')] = allsubs_singing_wilcoxon['p value']\n",
    "\n",
    "inspection_3[('singing_RH-nM','median')] = rhnm_singing_stats['median']\n",
    "inspection_3[('singing_RH-nM','mean')] = rhnm_singing_stats['mean']\n",
    "inspection_3[('singing_RH-nM','std')] = rhnm_singing_stats['sd']\n",
    "inspection_3[('singing_RH-nM','p_value')] = rhnm_singing_wilcoxon['p value']\n",
    "\n",
    "inspection_3[('singing_RH-M','median')] = rhm_singing_stats['median']\n",
    "inspection_3[('singing_RH-M','mean')] = rhm_singing_stats['mean']\n",
    "inspection_3[('singing_RH-M','std')] = rhm_singing_stats['sd']\n",
    "inspection_3[('singing_RH-M','p_value')] = rhm_singing_wilcoxon['p value']\n",
    "\n",
    "inspection_3[('singing_LH-nM','median')] = lhnm_singing_stats['median']\n",
    "inspection_3[('singing_LH-nM','mean')] = lhnm_singing_stats['mean']\n",
    "inspection_3[('singing_LH-nM','std')] = lhnm_singing_stats['sd']\n",
    "inspection_3[('singing_LH-nM','p_value')] = lhnm_singing_wilcoxon['p value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspection_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_3 = inspection_3.iloc[:,0:4]\n",
    "table_allsubs_3 = allsubs_3.to_csv('statistics_B-matrices_singing_allsubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhnm_3 = inspection_3.iloc[:,4:8]\n",
    "table_rhnm_3 = rhnm_3.to_csv('statistics_B-matrices_singing_rhnm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_3 = inspection_3.iloc[:,8:12]\n",
    "table_rhm_3 = rhm_3.to_csv('statistics_B-matrices_singing_rhm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhnm_3 = inspection_3.iloc[:,12:16]\n",
    "table_lhnm_3 = lhnm_3.to_csv('statistics_B-matrices_singing_lhnm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create table-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhm_3.index.names = ['connection']\n",
    "df2 = rhm_3.reset_index().transpose()\n",
    "df2\n",
    "df3 = df2.reset_index()\n",
    "df3\n",
    "df3.ix[df3.duplicated('level_0') , 'level_0'] = '' \n",
    "df4 = df3.transpose()\n",
    "df4.columns = df4.iloc[0]\n",
    "final_table = df4.reindex()\n",
    "table_2 = final_table.drop(['level_0'])\n",
    "table_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "\n",
    "def render_mpl_table(data, col_width=0.2, row_height=1, font_size=16,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=1,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        #size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=(16,8))\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in  six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            #cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors)])\n",
    "    return ax\n",
    "\n",
    "figure_1 = render_mpl_table(table_2, header_columns=1, col_width=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = figure_1.get_figure()\n",
    "fig_1.savefig(\"table-rhm-singing.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hypothesis: differences in modulatory effective connectivities: modulatory inputs speech, singing, music\n",
    "### group rhnm as control-sample (music vs speech, music vs singing, speech vs singing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(con_params_B_matrices_music)\n",
    "display(con_params_B_matrices_singing)\n",
    "display(con_params_B_matrices_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_A_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### music vs speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_vs_allsubs_speech = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_music.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_B_matrices_music[con], con_params_B_matrices_speech[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_B_matrices_music[con], con_params_B_matrices_speech[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_vs_allsubs_speech['statistic'] = list_mannwhitney_stats\n",
    "allsubs_music_vs_allsubs_speech['p value'] = list_mannwhitney_p\n",
    "allsubs_music_vs_allsubs_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### music vs singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_vs_allsubs_singing = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_music.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_B_matrices_music[con], con_params_B_matrices_singing[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_B_matrices_music[con], con_params_B_matrices_singing[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_music_vs_allsubs_singing['statistic'] = list_mannwhitney_stats\n",
    "allsubs_music_vs_allsubs_singing['p value'] = list_mannwhitney_p\n",
    "allsubs_music_vs_allsubs_singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PP_r → HG_r \t119.5 \t0.008899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speech vs singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_vs_allsubs_singing = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_B_matrices_music.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_B_matrices_speech[con], con_params_B_matrices_singing[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_B_matrices_speech[con], con_params_B_matrices_singing[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs_speech_vs_allsubs_singing['statistic'] = list_mannwhitney_stats\n",
    "allsubs_speech_vs_allsubs_singing['p value'] = list_mannwhitney_p\n",
    "allsubs_speech_vs_allsubs_singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP_l → HG_l \t107.5 \t0.005488"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hypothesis: differences in modulatory effective connectivities for inputs speech, singing, music between\n",
    "### rhnm, rhm, lhnm (music-rhnm vs music-rhm, music-rhnm vs music-lhnm, music-rhm vs music-lhnm, speech...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 contrasts\n",
    "display(con_params_music_rhnm)\n",
    "display(con_params_music_rhm)\n",
    "display(con_params_music_lhnm)\n",
    "display(con_params_speech_rhnm)\n",
    "display(con_params_speech_rhm)\n",
    "display(con_params_speech_lhnm)\n",
    "display(con_params_singing_rhnm)\n",
    "display(con_params_singing_rhm)\n",
    "display(con_params_singing_lhnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### music-rhnm vs music-rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_rhnm_vs_music_rhm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_music_rhnm[con], con_params_music_rhm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_music_rhnm[con], con_params_music_rhm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_rhnm_vs_music_rhm['statistic'] = list_mannwhitney_stats\n",
    "music_rhnm_vs_music_rhm['p value'] = list_mannwhitney_p\n",
    "music_rhnm_vs_music_rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP_r → HG_r \t15.0 \t0.031001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### music-rhnm vs music-lhnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_rhnm_vs_music_lhnm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_music_rhnm[con], con_params_music_lhnm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_music_rhnm[con], con_params_music_lhnm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_rhnm_vs_music_lhnm['statistic'] = list_mannwhitney_stats\n",
    "music_rhnm_vs_music_lhnm['p value'] = list_mannwhitney_p\n",
    "music_rhnm_vs_music_lhnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HG_r → PT_r \t7.0 \t0.047795"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### music-lhnm vs music-rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_lhnm_vs_music_rhm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_music_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_music_lhnm[con], con_params_music_rhm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_music_lhnm[con], con_params_music_rhm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_lhnm_vs_music_rhm['statistic'] = list_mannwhitney_stats\n",
    "music_lhnm_vs_music_rhm['p value'] = list_mannwhitney_p\n",
    "music_lhnm_vs_music_rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### singing-rhnm vs singing-rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singing_rhnm_vs_singing_rhm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_singing_rhnm[con], con_params_singing_rhm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_singing_rhnm[con], con_params_singing_rhm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singing_rhnm_vs_singing_rhm['statistic'] = list_mannwhitney_stats\n",
    "singing_rhnm_vs_singing_rhm['p value'] = list_mannwhitney_p\n",
    "singing_rhnm_vs_singing_rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HG_r → HG_r \t15.0 \t0.045169\n",
    "# PP_l → HG_l \t15.0 \t0.042799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### singing-rhnm vs singing-lhnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singing_rhnm_vs_singing_lhnm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_singing_rhnm[con], con_params_singing_lhnm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_singing_rhnm[con], con_params_singing_lhnm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singing_rhnm_vs_singing_lhnm['statistic'] = list_mannwhitney_stats\n",
    "singing_rhnm_vs_singing_lhnm['p value'] = list_mannwhitney_p\n",
    "singing_rhnm_vs_singing_lhnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HG_r → PP_r \t8.0 \t0.047325\n",
    "# PT_r → HG_r \t7.0 \t0.047795"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### singing-lhnm vs singing-rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singing_lhnm_vs_singing_rhm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_singing_lhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_singing_lhnm[con], con_params_singing_rhm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_singing_lhnm[con], con_params_singing_rhm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singing_lhnm_vs_singing_rhm['statistic'] = list_mannwhitney_stats\n",
    "singing_lhnm_vs_singing_rhm['p value'] = list_mannwhitney_p\n",
    "singing_lhnm_vs_singing_rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT_l → HG_l \t4.0 \t0.035002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speech-rhnm vs speech-rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_rhnm_vs_speech_rhm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_speech_rhnm[con], con_params_speech_rhm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_speech_rhnm[con], con_params_speech_rhm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_rhnm_vs_speech_rhm['statistic'] = list_mannwhitney_stats\n",
    "speech_rhnm_vs_speech_rhm['p value'] = list_mannwhitney_p\n",
    "speech_rhnm_vs_speech_rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speech-rhnm vs speech-lhnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_rhnm_vs_speech_lhnm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_speech_rhnm[con], con_params_speech_lhnm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_speech_rhnm[con], con_params_speech_lhnm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_rhnm_vs_speech_lhnm['statistic'] = list_mannwhitney_stats\n",
    "speech_rhnm_vs_speech_lhnm['p value'] = list_mannwhitney_p\n",
    "speech_rhnm_vs_speech_lhnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP_r → HG_r \t8.0 \t0.047325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speech-lhnm vs speech-rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Mann Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_lhnm_vs_speech_rhm = pd.DataFrame(columns=['statistic', 'p value'], index=index_A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mannwhitney_stats = []\n",
    "list_mannwhitney_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik über sämtliche parameter der subs innerhalb einer Verbindung (als key gesetzt)\n",
    "for con in con_params_speech_rhnm.keys()[2:,]:\n",
    "    \n",
    "    list_mannwhitney_stats.append(round(stats.mannwhitneyu(con_params_speech_lhnm[con], con_params_speech_rhm[con])[0], 12))\n",
    "    list_mannwhitney_p.append(round(stats.mannwhitneyu(con_params_speech_lhnm[con], con_params_speech_rhm[con])[1], 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_lhnm_vs_speech_rhm['statistic'] = list_mannwhitney_stats\n",
    "speech_lhnm_vs_speech_rhm['p value'] = list_mannwhitney_p\n",
    "speech_lhnm_vs_speech_rhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
