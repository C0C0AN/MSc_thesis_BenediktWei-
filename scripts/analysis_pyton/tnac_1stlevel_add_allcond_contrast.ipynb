{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import important modules #####\n",
    "\n",
    "from os.path import join as opj\n",
    "from nipype.interfaces.spm import Level1Design,EstimateModel, EstimateContrast\n",
    "import nipype.interfaces.spm as spm\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.algorithms.modelgen import SpecifySPMModel\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path to spm standalone and MCR\n",
    "matlab_cmd = '/usr/local/spm12/run_spm12.sh /usr/local/MCR/v713/ script'\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Specify interface behaviors #####\n",
    "\n",
    "# Matlab - Specify path to current SPM and the MATLAB's default mode, comment these lines if you're using the standalone version of SPM\n",
    "#from nipype.interfaces.matlab import MatlabCommand\n",
    "#MatlabCommand.set_default_paths('/usr/local/MATLAB/R2016b/toolbox/spm12/') # set the path to your local spm folder\n",
    "#MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = '/media/lmn/86A406A0A406933B2/TNAC_BIDS/'\n",
    "output_dir = 'derivatives/1stlevel/output_1stlevel_allcond'\n",
    "working_dir = 'derivatives/1stlevel/workingdir_1stlevel_allcond'\n",
    "input_dir_preproc = 'derivatives/preprocessing/output_preproc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of subjects\n",
    "subject_list = ['sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10', 'sub-11', 'sub-12', 'sub-13', 'sub-14', 'sub-15', 'sub-16', 'sub-17', 'sub-18', 'sub-19', 'sub-20', 'sub-21', 'sub-22', 'sub-23', 'sub-24'] \n",
    "\n",
    "TR = 1.45   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create & specify nodes to be used and connected during the 1st level pipeline #####\n",
    "\n",
    "# SpecifyModel - Generates SPM-specific Model\n",
    "modelspec = Node(SpecifySPMModel(concatenate_runs=False,\n",
    "                                 input_units='secs',\n",
    "                                 output_units='secs',\n",
    "                                 time_repetition=TR,\n",
    "                                 high_pass_filter_cutoff=128),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# Level1Design - Generates an SPM design matrix\n",
    "level1design_masks = Node(Level1Design(bases={'hrf': {'derivs': [0, 0]}},\n",
    "                                 timing_units='secs',\n",
    "                                 interscan_interval=TR,\n",
    "                                 model_serial_correlations='AR(1)'),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# EstimateModel - estimate the parameters of the model\n",
    "level1estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level1estimate\")\n",
    "\n",
    "# EstimateContrast - estimates contrasts\n",
    "conestimate = Node(EstimateContrast(), name=\"conestimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='l1analysis')\n",
    "l1analysis.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(modelspec, level1design_masks, [('session_info',\n",
    "                                                'session_info')]),\n",
    "                    (level1design_masks, level1estimate, [('spm_mat_file',\n",
    "                                                     'spm_mat_file')]),\n",
    "                    #(level1estimate, conestimate, [('spm_mat_file',\n",
    "                    #                                'spm_mat_file'),\n",
    "                    #                               ('beta_images',\n",
    "                    #                                'beta_images'),\n",
    "                     #                              ('residual_image',\n",
    "                    #                                'residual_image')]),\n",
    "                    ])\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import Bunch\n",
    "def get_subject_info(subject_id):\n",
    "    from os.path import join as opj\n",
    "    import pandas as pd\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    path = '/media/lmn/86A406A0A406933B2/TNAC_BIDS/%s/func'%subject_id\n",
    "    for run in ['1', '2', '3', '4']:\n",
    "        file = pd.read_table(opj(path, subject_id+'_task-tnac_'+'run-'+run+'_events.tsv'))\n",
    "        # sort stimuli/rows so that they are always in the same order\n",
    "        file['stimuli_cat'] = pd.Categorical(file['block_modality'], categories=['block_music', 'block_song', 'block_voice'], ordered=True)\n",
    "        sorted_file = file.sort_values('stimuli_cat')\n",
    "\n",
    "        # create lists for each run including the stimuli and their particular onset times\n",
    "        onset_array = []\n",
    "        duration_array = []\n",
    "        stimuli_array = []\n",
    "        for group in sorted_file.groupby('block_modality', sort=False):\n",
    "            stimuli_array.append(group[0])\n",
    "            onset_array.append(list(round(group[1].corr_block_start,1)))\n",
    "            duration_array.append(list(round(group[1].block_duration,1)))\n",
    "            \n",
    "        all_cond_onset = onset_array[0] + onset_array[1] + onset_array[2] \n",
    "        all_cond_dur = duration_array[0] + duration_array[1] + duration_array[2]    \n",
    "        onset_array.append(all_cond_onset)\n",
    "        duration_array.append(all_cond_dur)\n",
    "        stimuli_array.append(\"all_cond\")\n",
    "    \n",
    "        if run == '1':\n",
    "            info_run1 = [stimuli_array, onset_array, duration_array]\n",
    "        elif run == '2':\n",
    "            info_run2 = [stimuli_array, onset_array, duration_array]\n",
    "        elif run == '3':\n",
    "            info_run3 = [stimuli_array, onset_array, duration_array]\n",
    "        elif run == '4':\n",
    "            info_run4 = [stimuli_array, onset_array, duration_array]\n",
    "        else:\n",
    "            print(info_run_error)\n",
    "\n",
    "    # create subject_info including all runs\n",
    "    subject_info=[]\n",
    "    for r in range(4):\n",
    "        if r == 0:\n",
    "            subject_info.insert(r,\n",
    "                                (Bunch(conditions=info_run1[0],\n",
    "                                 onsets = info_run1[1],\n",
    "                                 durations = info_run1[2],\n",
    "                                 amplitudes=None,\n",
    "                                 tmod=None,\n",
    "                                 pmod=None)))   \n",
    "        elif r == 1:\n",
    "            subject_info.insert(r,\n",
    "                                (Bunch(conditions=info_run2[0],\n",
    "                                 onsets = info_run2[1],\n",
    "                                 durations = info_run2[2],\n",
    "                                 amplitudes=None,\n",
    "                                 tmod=None,\n",
    "                                 pmod=None))) \n",
    "        elif r == 2:\n",
    "            subject_info.insert(r,\n",
    "                                (Bunch(conditions=info_run3[0],\n",
    "                                 onsets = info_run3[1],\n",
    "                                 durations = info_run3[2],\n",
    "                                 amplitudes=None,\n",
    "                                 tmod=None,\n",
    "                                 pmod=None)))\n",
    "        elif r == 3:\n",
    "            subject_info.insert(r,\n",
    "                                (Bunch(conditions=info_run4[0],\n",
    "                                 onsets = info_run4[1],\n",
    "                                 durations = info_run4[2],\n",
    "                                 amplitudes=None,\n",
    "                                 tmod=None,\n",
    "                                 pmod=None)))\n",
    "\n",
    "        else: \n",
    "            print(\"error2\")          \n",
    "            \n",
    "    return(subject_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subject info - get subject specific condition information\n",
    "getsubjectinfo = Node(Function(input_names=['subject_id'],\n",
    "                               output_names=['subject_info'],\n",
    "                               function=get_subject_info),\n",
    "                      name='getsubjectinfo')\n",
    "\n",
    "### Define model specific contrasts\n",
    "\n",
    "# condition names\n",
    "condition_names = ['block_music', 'block_song', 'block_voice', 'all_cond'] # enter the condition names of your study\n",
    "\n",
    "# contrasts; name your contrasts, specify if T or F, enter contrast vector (also the 6 motion-parameters--> 6 zeros more!)\n",
    "contrast01 = ['block_music', 'T', condition_names, [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]*4]\n",
    "contrast02 = ['block_song', 'T', condition_names, [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]*4]\n",
    "contrast03 = ['block_voice', 'T', condition_names, [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]*4]\n",
    "contrast04 = ['all_conditions', 'T', condition_names, [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]*4]\n",
    "#contrast05 = ['activation', 'F', [contrast01, contrast02, contrast03]]\n",
    "\n",
    "contrast_list = [contrast01, contrast02, contrast03, contrast04]#, contrast05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Specify input and output stream #####\n",
    "\n",
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id',\n",
    "                                            'contrasts'],\n",
    "                                    contrasts=contrast_list),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "templates = {'func_smooth': opj(input_dir_preproc, 'smooth', '{subject_id}',  'sr{subject_id}_*.nii'),\n",
    "             'realign_par': opj(input_dir_preproc, 'realign', '{subject_id}', 'rp_{subject_id}_*.txt'),\n",
    "             'mask': opj(input_dir_preproc, 'masks', '{subject_id}', 'aparc_robust_BET.nii')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory=experiment_dir),\n",
    "                   name=\"selectfiles\")\n",
    "       \n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### establish input and output streams by connecting Infosource, SelectFiles and DataSink to the main workflow #####\n",
    "l1analysis.connect([(infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                  (selectfiles, modelspec,[('func_smooth', 'functional_runs')]),  \n",
    "                  (selectfiles, modelspec,[('realign_par', 'realignment_parameters')]),\n",
    "                  (selectfiles, level1design_masks, [('mask', 'mask_image')]),\n",
    "                  (infosource, getsubjectinfo, [('subject_id', 'subject_id')]),\n",
    "                  (getsubjectinfo, modelspec, [('subject_info',\n",
    "                                                 'subject_info')]),\n",
    "                  #(infosource, conestimate, [('contrasts',\n",
    "                  #                           'contrasts')]),\n",
    "                  (level1estimate, datasink, [('mask_image', 'contrasts.@mask'),\n",
    "                                              ('spm_mat_file','contrasts.@spm_mat')]), \n",
    "                  #(conestimate, datasink, [('spm_mat_file',\n",
    "                  #                         'contrasts.@spm_mat'),\n",
    "                  #                        ('spmT_images',\n",
    "                  #                         'contrasts.@T'),\n",
    "                   #                       ('con_images',\n",
    "                   #                        'contrasts.@con')]),\n",
    "                   ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### visualize the pipeline ####\n",
    "\n",
    "# Create a colored mvpaflow output graph\n",
    "l1analysis.write_graph(graph2use='colored',format='png', simple_form=True)\n",
    "\n",
    "# Create a detailed mvpaflow output graph\n",
    "l1analysis.write_graph(graph2use='flat',format='png', simple_form=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize graphs\n",
    "from IPython.display import Image\n",
    "Image(filename='/media/lmn/86A406A0A406933B2/TNAC_BIDS/derivatives/1stlevel/workingdir_1stlevel/l1analysis/graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image(filename='/media/lmn/86A406A0A406933B2/TNAC_BIDS/derivatives/1stlevel/workingdir_1stlevel/l1analysis/graph_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### run the workflow using multiple cores ####\n",
    "l1analysis.run('MultiProc', plugin_args={'n_procs':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree /media/lmn/86A406A0A406933B2/TNAC_BIDS/derivatives/1stlevel/output_1stlevel_allcond/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
